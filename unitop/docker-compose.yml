version: '3.7'

services:
  # test_crawl:
  #   # image: imagecrawler
  #   build:
  #     context: .
  #     dockerfile: Dockerfile
  #   container_name: test_crawl
  #   # volumes:
  #     # - ./unitop:/usr/src/app
  #   networks: 
  #     - mynetwork
  #   depends_on:
  #     - mongo

  mongo:
    image: mongo:4.4
    container_name: mongo
    ports:
      - "27020:27017"  # map the MongoDB port to the host
    environment:
      MONGO_INITDB_ROOT_USERNAME: root  # set the root username
      MONGO_INITDB_ROOT_PASSWORD: rootpassword  # set the root password
    volumes:
      - ./mongo-data:/data/db  # persist the database data
    networks:
      - mynetwork
    healthcheck:
      test: ["CMD-SHELL", "mongo --eval 'db.adminCommand(\"ping\")' || exit 1"]  # check MongoDB health by pinging it
      interval: 10s  # how often to run the check (every 10 seconds)
      timeout: 5s    # time to wait for the check to complete (5 seconds)
      retries: 5     # if it fails, how many times to retry
      start_period: 30s  # time to wait before starting health checks (allows MongoDB to initialize)

  # test_mongodb:
  #   image: mongo
  #   container_name: mongodb
  #   ports:
  #     - "27017:27017"
  #   networks: 
  #     - mynetwork

  # spark-master:
  #   image: bitnami/spark:latest
  #   command: bin/spark-class org.apache.spark.deploy.master.Master
  #   ports:
  #     - "9090:8080"
  #     - "7077:7077"
  #   networks:
  #     - mynetwork

  # spark-worker:
  #   image: bitnami/spark:latest
  #   command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  #   depends_on:
  #     - spark-master
  #   environment:
  #     SPARK_MODE: worker
  #     SPARK_WORKER_CORES: 2
  #     SPARK_WORKER_MEMORY: 1g
  #     SPARK_MASTER_URL: spark://spark-master:7077
  #   networks:
  #     - mynetwork

  # spark-master:
  #   image: bitnami/spark:latest
  #   container_name: spark-master
  #   command: bin/spark-class org.apache.spark.deploy.master.Master
  #   environment:
  #     SPARK_SUBMIT_ARGS: "--packages org.mongodb.spark:mongo-spark-connector_2.12:10.0.0 pyspark-shell"
  #   ports:
  #     - "8080:8080"  # Web UI
  #     - "7077:7077"  # Spark Master Port
  #   networks:
  #     - mynetwork

  # spark-worker:
  #   image: bitnami/spark:latest
  #   container_name: spark-worker
  #   command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  #   depends_on:
  #     - spark-master
  #   environment:
  #     SPARK_MODE: worker
  #     SPARK_WORKER_CORES: 2
  #     SPARK_WORKER_MEMORY: 1g
  #     SPARK_MASTER_URL: spark://spark-master:7077
  #     SPARK_SUBMIT_ARGS: "--packages org.mongodb.spark:mongo-spark-connector_2.12:10.0.0 pyspark-shell"
  #   networks:
  #     - mynetwork

  spark:
    image: apache/spark:latest
    container_name: spark
    
    networks:
      - mynetwork


networks:
  mynetwork:
    driver: bridge

volumes:
  mongo-data:
    name: mongo-datalake